"""
LoRA Training Script for DiffSynth-Studio Z-Image Model
This script uses the configuration generated by the UI
"""

import os
import json
import argparse
from pathlib import Path
from typing import Optional
import torch
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.optim import AdamW
from tqdm import tqdm
import numpy as np
from PIL import Image

try:
    from diffsynth import DiffSynthModel
    from peft import get_peft_model, LoraConfig, TaskType
    from transformers import CLIPTokenizer, CLIPTextModel
except ImportError:
    print("Required packages not found. Please install dependencies:")
    print("pip install -r requirements.txt")
    exit(1)


class ImageDataset(Dataset):
    """Dataset for loading training images"""
    
    def __init__(self, dataset_path: str, image_size: int = 512, 
                 center_crop: bool = True, random_flip: bool = True):
        self.dataset_path = Path(dataset_path)
        self.image_size = image_size
        self.center_crop = center_crop
        self.random_flip = random_flip
        
        # Supported image formats
        self.image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.webp']:
            self.image_files.extend(self.dataset_path.glob(f'**/{ext}'))
            self.image_files.extend(self.dataset_path.glob(f'**/{ext.upper()}'))
        
        if not self.image_files:
            raise ValueError(f"No images found in {dataset_path}")
        
        print(f"Found {len(self.image_files)} images for training")
    
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        img_path = self.image_files[idx]
        
        try:
            image = Image.open(img_path).convert('RGB')
            
            # Resize
            if self.center_crop:
                # Center crop to square
                min_dim = min(image.size)
                left = (image.width - min_dim) // 2
                top = (image.height - min_dim) // 2
                right = left + min_dim
                bottom = top + min_dim
                image = image.crop((left, top, right, bottom))
            
            image = image.resize((self.image_size, self.image_size), 
                                Image.Resampling.LANCZOS)
            
            # Random flip
            if self.random_flip and np.random.rand() > 0.5:
                image = image.transpose(Image.Transpose.FLIP_LEFT_RIGHT)
            
            # Convert to tensor
            image = np.array(image).astype(np.float32) / 255.0
            image = torch.from_numpy(image).permute(2, 0, 1)
            
            # Normalize
            image = 2 * image - 1  # [-1, 1]
            
            return {'image': image, 'image_path': str(img_path)}
            
        except Exception as e:
            print(f"Error loading {img_path}: {e}")
            # Return black image on error
            return {'image': torch.zeros(3, self.image_size, self.image_size),
                   'image_path': str(img_path)}


class LoRATrainer:
    """Trainer for LoRA fine-tuning"""
    
    def __init__(self, config_path: str, device: str = 'cuda' if torch.cuda.is_available() else 'cpu'):
        self.device = device
        self.config_path = Path(config_path)
        self.lora_dir = self.config_path.parent
        
        # Load configuration
        with open(config_path) as f:
            self.config = json.load(f)
        
        self.setup_directories()
        self.setup_model()
        self.setup_training()
    
    def setup_directories(self):
        """Create necessary directories"""
        self.dataset_dir = self.lora_dir / 'dataset'
        self.checkpoint_dir = self.lora_dir / 'checkpoints'
        self.log_dir = self.lora_dir / 'logs'
        
        self.dataset_dir.mkdir(exist_ok=True)
        self.checkpoint_dir.mkdir(exist_ok=True)
        self.log_dir.mkdir(exist_ok=True)
        
        print(f"Dataset directory: {self.dataset_dir}")
        print(f"Checkpoint directory: {self.checkpoint_dir}")
    
    def setup_model(self):
        """Setup model with LoRA adapters"""
        print("Loading base model...")
        
        try:
            # Load DiffSynth model
            self.model = DiffSynthModel.from_pretrained(
                self.config['model_reasoning']['base_model']
            )
        except Exception as e:
            print(f"Warning: Could not load DiffSynth model: {e}")
            print("Please ensure Z-Image-i2 is downloaded")
            raise
        
        # Setup LoRA
        print("Applying LoRA adapters...")
        lora_config = LoraConfig(
            r=self.config['lora_config']['rank'],
            lora_alpha=self.config['lora_config']['alpha'],
            target_modules=self.config['lora_config']['target_modules'],
            lora_dropout=self.config['lora_config']['r_dropout'],
            bias=self.config['lora_config']['bias'],
            task_type=TaskType.FEATURE_EXTRACTION,
        )
        
        # Apply LoRA to model
        self.model = get_peft_model(self.model, lora_config)
        self.model.print_trainable_parameters()
        self.model.to(self.device)
    
    def setup_training(self):
        """Setup training components"""
        self.optimizer = AdamW(
            self.model.parameters(),
            lr=self.config['training']['learning_rate'],
            weight_decay=self.config['training']['weight_decay']
        )
        
        self.num_epochs = self.config['training']['num_epochs']
        self.batch_size = self.config['training']['batch_size']
        self.steps_per_epoch = self.config['training']['steps_per_epoch']
        self.warmup_steps = self.config['training']['warmup_steps']
        self.save_steps = self.config['training']['save_steps']
        self.logging_steps = self.config['training']['logging_steps']
    
    def get_dataloader(self):
        """Create data loader"""
        if not list(self.dataset_dir.glob('*')):
            raise FileNotFoundError(
                f"No images found in {self.dataset_dir}\n"
                f"Please add training images to this directory"
            )
        
        dataset = ImageDataset(
            str(self.dataset_dir),
            image_size=self.config['data']['image_size'],
            center_crop=self.config['data']['center_crop'],
            random_flip=self.config['data']['random_flip']
        )
        
        dataloader = DataLoader(
            dataset,
            batch_size=self.batch_size,
            shuffle=True,
            num_workers=0,  # Set to 0 to avoid issues on Windows
            pin_memory=True if self.device == 'cuda' else False
        )
        
        return dataloader
    
    def train_epoch(self, dataloader, epoch: int):
        """Train for one epoch"""
        self.model.train()
        total_loss = 0.0
        step = epoch * self.steps_per_epoch
        
        pbar = tqdm(dataloader, total=min(len(dataloader), self.steps_per_epoch),
                   desc=f"Epoch {epoch + 1}/{self.num_epochs}")
        
        for batch_idx, batch in enumerate(pbar):
            if batch_idx >= self.steps_per_epoch:
                break
            
            images = batch['image'].to(self.device)
            
            # Forward pass
            self.optimizer.zero_grad()
            
            try:
                # Add noise and predict noise (simplified training objective)
                noise = torch.randn_like(images)
                timesteps = torch.randint(0, 1000, (images.shape[0],)).to(self.device)
                
                # Model inference (simplified - adapt to actual DiffSynth API)
                with torch.autocast(device_type=self.device):
                    outputs = self.model(images, timesteps)
                    loss = F.mse_loss(outputs, noise)
                
                # Backward pass
                loss.backward()
                torch.nn.utils.clip_grad_norm_(
                    self.model.parameters(),
                    self.config['training']['max_grad_norm']
                )
                self.optimizer.step()
                
                total_loss += loss.item()
                
                if (batch_idx + 1) % self.logging_steps == 0:
                    avg_loss = total_loss / (batch_idx + 1)
                    pbar.set_postfix({'loss': f'{avg_loss:.4f}'})
                
                # Save checkpoint
                if (batch_idx + 1) % self.save_steps == 0:
                    self.save_checkpoint(epoch, batch_idx)
                
            except Exception as e:
                print(f"Error in training step: {e}")
                continue
        
        avg_loss = total_loss / min(len(dataloader), self.steps_per_epoch)
        print(f"Epoch {epoch + 1} - Avg Loss: {avg_loss:.4f}")
        
        return avg_loss
    
    def save_checkpoint(self, epoch: int, step: int):
        """Save model checkpoint"""
        checkpoint_path = self.checkpoint_dir / f"epoch_{epoch:03d}_step_{step:05d}"
        checkpoint_path.mkdir(exist_ok=True)
        
        self.model.save_pretrained(str(checkpoint_path))
        print(f"✓ Checkpoint saved: {checkpoint_path}")
    
    def train(self):
        """Main training loop"""
        print(f"\n{'='*60}")
        print(f"Starting LoRA Training")
        print(f"{'='*60}")
        print(f"Configuration: {self.config['name']}")
        print(f"Base Model: {self.config['model_reasoning']['base_model']}")
        print(f"LoRA Rank: {self.config['lora_config']['rank']}")
        print(f"Epochs: {self.num_epochs}")
        print(f"Batch Size: {self.batch_size}")
        print(f"Device: {self.device}")
        print(f"{'='*60}\n")
        
        try:
            dataloader = self.get_dataloader()
        except FileNotFoundError as e:
            print(f"Error: {e}")
            return
        
        best_loss = float('inf')
        losses = []
        
        for epoch in range(self.num_epochs):
            epoch_loss = self.train_epoch(dataloader, epoch)
            losses.append(epoch_loss)
            
            if epoch_loss < best_loss:
                best_loss = epoch_loss
                self.save_checkpoint(epoch, 0)
                print(f"✓ New best model saved (loss: {best_loss:.4f})")
            
            # Save config with losses
            self.config['training_history'] = {
                'losses': losses,
                'best_loss': best_loss,
                'completed_epochs': epoch + 1
            }
        
        # Final save
        final_save_path = self.checkpoint_dir / 'final'
        final_save_path.mkdir(exist_ok=True)
        self.model.save_pretrained(str(final_save_path))
        
        # Save config
        with open(self.lora_dir / 'config.json', 'w') as f:
            json.dump(self.config, f, indent=2)
        
        print(f"\n{'='*60}")
        print(f"Training Complete!")
        print(f"Best Loss: {best_loss:.4f}")
        print(f"Final Model: {final_save_path}")
        print(f"{'='*60}\n")


def main():
    parser = argparse.ArgumentParser(
        description="Train LoRA adapters for DiffSynth-Studio Z-Image"
    )
    parser.add_argument(
        "--config",
        required=True,
        help="Path to LoRA configuration file (config.json)"
    )
    parser.add_argument(
        "--device",
        default="cuda" if torch.cuda.is_available() else "cpu",
        help="Device to use (cuda or cpu)"
    )
    
    args = parser.parse_args()
    
    # Validate config file
    config_path = Path(args.config)
    if not config_path.exists():
        print(f"Error: Config file not found: {config_path}")
        exit(1)
    
    # Create and run trainer
    trainer = LoRATrainer(str(config_path), device=args.device)
    trainer.train()


if __name__ == "__main__":
    main()
